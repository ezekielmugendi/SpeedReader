#' A function that implements a number of feature selection methods for finding top
#' words which distinguish between two classes.
#'
#' @param contingency_table A contingency table generated by the `contingency_table()` function.
#' @param rows_to_compare A numeric vector containing the indicies of two rows
#' in the contingency table we wish to compare against eachother. Defaults to
#' c(1,2). Currenlty only works for two category comparisons.
#' @param alpha The Dirichlet hyperparameter to be used if method =
#' "informed_Dirichlet". Suggested value is the average number of terms that
#' appear in a document. If a small value is selected, then more (globally)
#' common terms may be selected as top words. Increasing the value will select
#' for less globally common words. Defaults to 1 (not usually a good choice for
#' most analyses).
#' @param method Defaults to "informed_Dirichlet", which implements the model
#'  described in section 3.5.1 of Monroe et al. "Fightin Words...". Can also be
#'  "TF-IDF", in which case TF-IDF ranking is used (following equation 2 in
#'  "Fightin Words").
#' @param maximum_top_words Controls the maximum number of top words returned in
#' each category. Defaults to 5000.
#' @return A list object containing two dataframes (one for each comparison
#' category) with ranked top words. All words included in each dataset obtain
#' a z-score greater in magnitude than 1.96.
#' @export
feature_selection <- function(contingency_table,
                              rows_to_compare = c(1,2),
                              alpha = 1,
                              method = c("informed_Dirichlet",
                                         "TF-IDF"),
                              maximum_top_words = 5000){

    # make sure we only use one method
    method <- method[1]

    # determine whether we are working with a sparse matrix
    is_sparse_matrix <- FALSE
    if(class(contingency_table) == "simple_triplet_matrix"){
        is_sparse_matrix <- TRUE
    }

    # get the vocabulary
    vocabulary <- colnames(contingency_table)

    cat("Generating column sums...\n")
    # get column sums
    if(is_sparse_matrix){
        colsums <- as.numeric(slam::col_sums(contingency_table))
        category_1 <- as.numeric(slam::col_sums(contingency_table[rows_to_compare[1],]))
        category_2 <- as.numeric(slam::col_sums(contingency_table[rows_to_compare[2],]))
    }else{
        colsums <- as.numeric(apply(contingency_table,2,sum))
        category_1 <- as.numeric(contingency_table[rows_to_compare[1],])
        category_2 <- as.numeric(contingency_table[rows_to_compare[2],])
    }

    #############################################
    ######## INFORMED DIRICHLET RANKING #########
    #############################################
    if (method == "informed_Dirichlet") {
        # get the total number of tokens
        total_tokens <- sum(colsums)

        #calculate the prior contribution
        prior_contribution <- colsums * (alpha/total_tokens)

        cat("Calcualting log-odds ratios and variances...\n")
        # now calculate the log-odds ratio for each token
        log_odds_ratios <- log(category_1 + prior_contribution) -
            log(sum(category_1) + alpha - category_1 - prior_contribution) -
            log(category_2 + prior_contribution) +
            log(sum(category_2) + alpha - category_2 - prior_contribution)

        # calculate the variance of the log-odds ratio using equation 19
        variance <- 1/(category_1 + prior_contribution) +
            1/(sum(category_1) + alpha - category_1 - prior_contribution) +
            1/(category_2 + prior_contribution) +
            1/(sum(category_2) + alpha - category_2 - prior_contribution)

        # subset everything to remove any NaNs (this comes in if we are using a
        # subset of documents where some words do not appear at all in any of them)
        remove <- which(is.nan(log_odds_ratios))
        log_odds_ratios <- log_odds_ratios[-remove]
        variance <- variance[-remove]
        vocabulary <- vocabulary[-remove]
        category_1 <- category_1[-remove]
        category_2 <- category_2[-remove]

        # calculate z scores
        z_scores <- log_odds_ratios/sqrt(variance)

        #now get the significant words and rank them.
        cat("Finding top words in each category...\n\n")
        inds <- which(z_scores > 1.96)
        category_1_significant_words <- data.frame(
            term = vocabulary[inds],
            log_odds_ratio = log_odds_ratios[inds],
            variance = variance[inds],
            z_scores = z_scores[inds],
            count = category_1[inds],
            other_count = category_2[inds],
            stringsAsFactors = FALSE)
        rownames(category_1_significant_words) <- vocabulary[inds]
        ordering <- order(category_1_significant_words$z_scores,
                          decreasing = T)
        category_1_significant_words <- category_1_significant_words[ordering,]

        inds <- which(z_scores < -1.96)
        category_2_significant_words <- data.frame(
            term = vocabulary[inds],
            log_odds_ratio = log_odds_ratios[inds],
            variance = variance[inds],
            z_scores = z_scores[inds],
            count = category_2[inds],
            other_count = category_1[inds],
            stringsAsFactors = FALSE)
        rownames(category_2_significant_words) <- vocabulary[inds]
        ordering <- order(category_2_significant_words$z_scores,
                          decreasing = F)
        category_2_significant_words <- category_2_significant_words[ordering,]

        #print out resutls
        cat("Top 10 terms for category:",
            rownames(contingency_table)[rows_to_compare[1]], "...\n")
        print(head(category_1_significant_words[,2:6],n = 20))
        cat("\n\nTop 10 terms for category:",
            rownames(contingency_table)[rows_to_compare[2]], "...\n")
        print(head(category_2_significant_words[,2:6],n = 20))

        to_return <- list(c1 = category_1_significant_words,
                          c2 = category_2_significant_words)
    }

    #################################
    ######## TD-IDF RANKING #########
    #################################
    if (method == "TF-IDF") {
        # calcualte document frequency (not logged)
        doc_frequency <- rep(0, length(category_1))
        for (i in 1:length(doc_frequency)) {
            if (category_1[i] > 0) {
                doc_frequency[i] <- 1
            }
            if (category_2[i] > 0) {
                doc_frequency[i] <- doc_frequency[i]  + 1
            }
        }

        # now get rid of terms that do not appear in either document
        remove <- which(doc_frequency == 0)
        if (length(remove) > 0) {
            vocabulary <- vocabulary[-remove]
            category_1 <- category_1[-remove]
            category_2 <- category_2[-remove]
            doc_frequency <- doc_frequency[-remove]
        }

        # now calculate scores
        scores_1 <- category_1/doc_frequency
        #remove NaN entries
        vocabulary1 <- vocabulary
        category_11 <- category_1
        category_21 <- category_2
        doc_frequency1 <- doc_frequency
        remove <- which(is.nan(scores_1))
        if (length(remove) > 0) {
            scores_1 <- scores_1[remove]
            vocabulary1 <- vocabulary[-remove]
            category_11 <- category_1[-remove]
            category_21 <- category_2[-remove]
            doc_frequency1 <- doc_frequency[-remove]
        }

        # make the dataframe to return
        category_1_significant_words <- data.frame(
            term = vocabulary1,
            tfidf = scores_1,
            count = category_11,
            other_count = category_21,
            idf = doc_frequency1,
            stringsAsFactors = FALSE)
        rownames(category_1_significant_words) <- vocabulary1
        ordering <- order(category_1_significant_words$tfidf,
                          decreasing = T)
        category_1_significant_words <- category_1_significant_words[ordering,]


        # now calculate scores
        scores_2 <- category_2/doc_frequency
        #remove NaN entries
        vocabulary2 <- vocabulary
        category_22 <- category_2
        category_12 <- category_1
        doc_frequency2 <- doc_frequency
        remove <- which(is.nan(scores_1))
        if (length(remove) > 0) {
            scores_2 <- scores_2[remove]
            vocabulary2 <- vocabulary[-remove]
            category_22 <- category_2[-remove]
            category_12 <- category_1[-remove]
            doc_frequency2 <- doc_frequency[-remove]
        }

        # make the dataframe to return
        category_2_significant_words <- data.frame(
            term = vocabulary2,
            tfidf = scores_2,
            count = category_22,
            other_count = category_12,
            idf = doc_frequency2,
            stringsAsFactors = FALSE)
        rownames(category_2_significant_words) <- vocabulary2
        ordering <- order(category_2_significant_words$tfidf,
                          decreasing = T)
        category_2_significant_words <- category_2_significant_words[ordering,]

        #print out resutls
        cat("Top 10 terms for category:",
            rownames(contingency_table)[rows_to_compare[1]], "...\n")
        print(head(category_1_significant_words[,2:5],n = 20))
        cat("\n\nTop 10 terms for category:",
            rownames(contingency_table)[rows_to_compare[2]], "...\n")
        print(head(category_2_significant_words[,2:5],n = 20))

        to_return <- list(c1 = category_1_significant_words,
                          c2 = category_2_significant_words)

    }

    # make sure we do not excede the max number of words
    if (nrow(category_1_significant_words) > maximum_top_words) {
        category_1_significant_words <- category_1_significant_words[1:maximum_top_words,]
    }
    if (nrow(category_2_significant_words) > maximum_top_words) {
        category_2_significant_words <- category_2_significant_words[1:maximum_top_words,]
    }

    names(to_return) <- c(rownames(contingency_table)[rows_to_compare[1]],
                          rownames(contingency_table)[rows_to_compare[2]])

    return(to_return)
}
