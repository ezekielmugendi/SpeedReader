#' A function that implements a number of feature selection methods for finding top
#' words which distinguish between two classes.
#'
#' @param contingency_table A contingency table generated by the `contingency_table()` function.
#' @param rows_to_compare A numeric vector containing the indicies of two rows
#' in the contingency table we wish to compare against eachother. Defaults to
#' c(1,2)
#' @param alpha The Dirichlet hyperparameter to be used if method =
#' "informed_Dirichlet". Suggested value is the average number of terms that
#' appear in a document. If a small value is selected, then more (globally)
#' common terms may be selected as top words. Increasing the value will select
#' for less globally common words. Defaults to 1 (not usually a good choice for
#' most analyses).
#' @param method Currently only "informed_Dirichlet" is availalbe.
#' "informed_Dirichlet" implements the model described in section 3.5.1 of
#' Monroe et al. Fightin Words...
#' @return A list object containing two dataframes (one for each comparison
#' category) with ranked top words. All words included in each dataset obtain
#' a z-score greater in magnitude than 1.96.
#' @export
feature_selection <- function(contingency_table,
                              rows_to_compare = c(1,2),
                              alpha = 1,
                              method = "informed_Dirichlet"){

    # determine whether we are working with a sparse matrix
    is_sparse_matrix <- FALSE
    if(class(contingency_table) == "simple_triplet_matrix"){
        is_sparse_matrix <- TRUE
    }

    # get the vocabulary
    vocabulary <- colnames(contingency_table)

    cat("Generating column sums...\n")
    # get column sums
    if(is_sparse_matrix){
        colsums <- as.numeric(slam::col_sums(contingency_table))
        category_1 <- as.numeric(slam::col_sums(contingency_table[rows_to_compare[1],]))
        category_2 <- as.numeric(slam::col_sums(contingency_table[rows_to_compare[2],]))
    }else{
        colsums <- as.numeric(apply(contingency_table,2,sum))
        category_1 <- as.numeric(contingency_table[rows_to_compare[1],])
        category_2 <- as.numeric(contingency_table[rows_to_compare[2],])
    }

    # get the total number of tokens
    total_tokens <- sum(colsums)

    #calculate the prior contribution
    prior_contribution <- colsums * (alpha/total_tokens)

    cat("Calcualting log-odds ratios and variances...\n")
    # now calculate the log-odds ratio for each token
    log_odds_ratios <- log(category_1 + prior_contribution) -
        log(sum(category_1) + alpha - category_1 - prior_contribution) -
        log(category_2 + prior_contribution) +
        log(sum(category_2) + alpha - category_2 - prior_contribution)

    # calculate the variance of the log-odds ratio using equation 19
    variance <- 1/(category_1 + prior_contribution) +
        1/(sum(category_1) + alpha - category_1 - prior_contribution) +
        1/(category_2 + prior_contribution) +
        1/(sum(category_2) + alpha - category_2 - prior_contribution)

    # subset everything to remove any NaNs (this comes in if we are using a
    # subset of documents where some words do not appear at all in any of them)
    remove <- which(is.nan(log_odds_ratios))
    log_odds_ratios <- log_odds_ratios[-remove]
    variance <- variance[-remove]
    vocabulary <- vocabulary[-remove]

    # calculate z scores
    z_scores <- log_odds_ratios/sqrt(variance)

    #now get the significant words and rank them.
    cat("Finding top words in each category...\n")
    inds <- which(z_scores > 1.96)
    category_1_significant_words <- data.frame(
        term = vocabulary[inds],
        log_odds_ratio = log_odds_ratios[inds],
        variance = variance[inds],
        stringsAsFactors = FALSE)
    rownames(category_1_significant_words) <- vocabulary[inds]
    ordering <- order(category_1_significant_words$log_odds_ratio,
                      decreasing = T)
    category_1_significant_words <- category_1_significant_words[ordering,]

    inds <- which(z_scores < -1.96)
    category_2_significant_words <- data.frame(
        term = vocabulary[inds],
        log_odds_ratio = log_odds_ratios[inds],
        variance = variance[inds],
        stringsAsFactors = FALSE)
    rownames(category_2_significant_words) <- vocabulary[inds]
    ordering <- order(category_2_significant_words$log_odds_ratio,
                      decreasing = F)
    category_2_significant_words <- category_2_significant_words[ordering,]

    #print out resutls
    cat("Top 10 terms for category:",
        rownames(contingency_table)[rows_to_compare[1]], "...\n")
    print(head(category_1_significant_words[,2:3],n = 10))
    cat("\n\nTop 10 terms for category:",
        rownames(contingency_table)[rows_to_compare[2]], "...\n")
    print(head(category_2_significant_words[,2:3],n = 10))

    to_return <- list(c1 = category_1_significant_words,
                      c2 = category_2_significant_words)

    names(to_return) <- c(rownames(contingency_table)[rows_to_compare[1]],
                          rownames(contingency_table)[rows_to_compare[2]])

    return(to_return)
}
